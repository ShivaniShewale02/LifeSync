{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LifeSync â€” Production-Grade Cold-Start Personalization Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3b39cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf45afc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path('artifacts')\n",
    "BASE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "SCALER_PATH = BASE_DIR / 'scaler.joblib'\n",
    "PCA_PATH = BASE_DIR / 'pca.joblib'\n",
    "GMM_PATH = BASE_DIR / 'gmm.joblib'\n",
    "CLUSTER_MODEL_PATH = BASE_DIR / 'cluster_predictor.joblib'\n",
    "CLUSTER_PROFILES_PATH = BASE_DIR / 'cluster_profiles.json'\n",
    "INFLUENCE_MAP_PATH = BASE_DIR / 'feature_influence.json'\n",
    "\n",
    "N_CLUSTERS = 12\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "982a288e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (20000, 46)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('lifesync_synthetic_dataset_20k.csv')\n",
    "print('Dataset shape:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "757bb146",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLD_START_FEATURES = [\n",
    " 'sleep_quality','physical_activity_consistency','diet_quality','daily_energy_level','sedentary_level',\n",
    " 'stress_level','anxiety_level','mood_stability','mindfulness_habit','social_support',\n",
    " 'focus_ability','task_completion_reliability','distraction_level',\n",
    " 'financial_discipline','financial_stress'\n",
    "]\n",
    "\n",
    "FULL_FEATURES = [c for c in df.columns if c not in [\n",
    " 'health_score','mind_score','productivity_score','finance_score','life_score'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "240662b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sleep_quality'] = df['sleep_hours'] / 9 * 100\n",
    "df['physical_activity_consistency'] = df['exercise_days_per_week'] / 7 * 100\n",
    "df['diet_quality'] = df['diet_ratio']\n",
    "df['sedentary_level'] = df['sedentary_hours'] / 12 * 100\n",
    "\n",
    "df['stress_level'] = df['stress_score']\n",
    "df['anxiety_level'] = df['anxiety_score']\n",
    "df['mood_stability'] = df['mood_stability_score']\n",
    "df['mindfulness_habit'] = df['meditation_completion_ratio']\n",
    "df['social_support'] = (df['family_support_ratio'] + df['friends_support_ratio']) / 2\n",
    "\n",
    "df['focus_ability'] = df['focus_level']\n",
    "df['task_completion_reliability'] = df['task_completion_ratio']\n",
    "df['distraction_level'] = df['distraction_ratio']\n",
    "\n",
    "df['financial_discipline'] = df['expense_tracking_score']\n",
    "df['financial_stress'] = df['debt_pressure_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e0b8224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artifacts\\\\scaler.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_full = scaler.fit_transform(df[FULL_FEATURES])\n",
    "joblib.dump(scaler, SCALER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae606b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA dimensions: 18\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=0.9, random_state=RANDOM_STATE)\n",
    "X_pca = pca.fit_transform(X_full)\n",
    "joblib.dump(pca, PCA_PATH)\n",
    "print('PCA dimensions:', X_pca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef1fe076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artifacts\\\\gmm.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm = GaussianMixture(\n",
    " n_components=N_CLUSTERS,\n",
    " covariance_type='full',\n",
    " random_state=RANDOM_STATE\n",
    ")\n",
    "df['cluster_id'] = gmm.fit_predict(X_pca)\n",
    "joblib.dump(gmm, GMM_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0d756d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_profiles = {}\n",
    "\n",
    "for cid in range(N_CLUSTERS):\n",
    " data = df[df['cluster_id'] == cid][FULL_FEATURES]\n",
    " cluster_profiles[cid] = {\n",
    "  'mean': data.mean().to_dict(),\n",
    "  'std': data.std().fillna(0).to_dict(),\n",
    "  'p05': data.quantile(0.05).to_dict(),\n",
    "  'p95': data.quantile(0.95).to_dict()\n",
    " }\n",
    "\n",
    "with open(CLUSTER_PROFILES_PATH, 'w') as f:\n",
    " json.dump(cluster_profiles, f)\n",
    "\n",
    "cluster_profiles = {int(k): v for k, v in json.load(open(CLUSTER_PROFILES_PATH)).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb7ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[COLD_START_FEATURES]\n",
    "y = df['cluster_id']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    " X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "cluster_model = LGBMClassifier(\n",
    " n_estimators=300,\n",
    " max_depth=6,\n",
    " learning_rate=0.05,\n",
    " random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "cluster_model.fit(X_train, y_train)\n",
    "joblib.dump(cluster_model, CLUSTER_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c18b46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_influence = {\n",
    " 'sleep_hours': {'sleep_quality': 0.04, 'stress_level': -0.03},\n",
    " 'steps_count': {'physical_activity_consistency': 80, 'sedentary_level': -60},\n",
    " 'distraction_ratio': {'stress_level': 0.5},\n",
    " 'savings_ratio': {'financial_stress': -0.5}\n",
    "}\n",
    "\n",
    "with open(INFLUENCE_MAP_PATH, 'w') as f:\n",
    " json.dump(feature_influence, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19ed9cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_entropy(probs):\n",
    " probs = np.clip(probs, 1e-9, 1)\n",
    " return -np.sum(probs * np.log(probs)) / np.log(len(probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ae26abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_profile(user_15, probs):\n",
    " cid = np.random.choice(len(probs), p=probs)\n",
    " stats = cluster_profiles[cid]\n",
    "\n",
    " entropy = normalized_entropy(probs)\n",
    " confidence = 1 - entropy\n",
    "\n",
    " profile = {}\n",
    "\n",
    " for f in FULL_FEATURES:\n",
    "  base = stats['mean'].get(f, 0)\n",
    "  std = stats['std'].get(f, 1)\n",
    "\n",
    "  noise = np.random.normal(0, std * (0.15 + 0.35 * confidence))\n",
    "\n",
    "  influence = 0\n",
    "  for src, targets in feature_influence.items():\n",
    "   if f in targets:\n",
    "    influence += confidence * targets[f] * (user_15.get(src, 50) - 50)\n",
    "\n",
    "  value = base + influence + noise\n",
    "  value = max(stats['p05'].get(f, value), min(value, stats['p95'].get(f, value)))\n",
    "\n",
    "  profile[f] = value\n",
    "\n",
    " return profile, {'entropy': float(entropy), 'confidence': float(confidence)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46504aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_user_profile_from_json(user_json):\n",
    " for f in COLD_START_FEATURES:\n",
    "  if f not in user_json or not (0 <= user_json[f] <= 100):\n",
    "   raise ValueError(f'Invalid value for {f}')\n",
    "\n",
    " probs = cluster_model.predict_proba(pd.DataFrame([user_json]))[0]\n",
    " profile, meta = generate_full_profile(user_json, probs)\n",
    "\n",
    " return {\n",
    "  'cluster_probabilities': probs.tolist(),\n",
    "  'confidence': meta,\n",
    "  'generated_features': profile\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c377c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 0.406\n",
      "Top-3 Accuracy: 0.830\n",
      "Mean Cluster Entropy: 0.457\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, top_k_accuracy_score\n",
    "\n",
    "y_pred = cluster_model.predict(X_val)\n",
    "y_prob = cluster_model.predict_proba(X_val)\n",
    "\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "top3 = top_k_accuracy_score(y_val, y_prob, k=3)\n",
    "\n",
    "print(f\"Top-1 Accuracy: {acc:.3f}\")\n",
    "print(f\"Top-3 Accuracy: {top3:.3f}\")\n",
    "print(f\"Mean Cluster Entropy: {np.mean([normalized_entropy(p) for p in y_prob]):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ed149f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Normalized MAE: 0.27542771777991787\n"
     ]
    }
   ],
   "source": [
    "def normalized_mae(real, pred, low, high):\n",
    "    if high - low == 0:\n",
    "        return 0\n",
    "    return abs(real - pred) / (high - low)\n",
    "\n",
    "errors = []\n",
    "\n",
    "for i in range(200):\n",
    "    real_row = df.iloc[X_val.index[i]]\n",
    "    user_15 = X_val.iloc[i].to_dict()\n",
    "\n",
    "    probs = cluster_model.predict_proba(pd.DataFrame([user_15]))[0]\n",
    "    gen_profile, _ = generate_full_profile(user_15, probs)\n",
    "\n",
    "    cid = int(real_row[\"cluster_id\"])\n",
    "\n",
    "    for f in FULL_FEATURES:\n",
    "        err = normalized_mae(\n",
    "            real_row[f],\n",
    "            gen_profile[f],\n",
    "            cluster_profiles[cid][\"p05\"][f],\n",
    "            cluster_profiles[cid][\"p95\"][f]\n",
    "        )\n",
    "        errors.append(err)\n",
    "\n",
    "print(\"Mean Normalized MAE:\", np.mean(errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16d05741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stress vs Distraction: 0.49374141323240517\n",
      "Sleep vs Energy: 0.12999022658098294\n",
      "Debt vs Savings: -0.577274374028165\n"
     ]
    }
   ],
   "source": [
    "def correlation_check(feature_x, feature_y, samples=300):\n",
    "    xs, ys = [], []\n",
    "\n",
    "    for _ in range(samples):\n",
    "        row = X_val.sample(1).iloc[0]\n",
    "        probs = cluster_model.predict_proba(pd.DataFrame([row]))[0]\n",
    "        profile, _ = generate_full_profile(row.to_dict(), probs)\n",
    "\n",
    "        xs.append(profile[feature_x])\n",
    "        ys.append(profile[feature_y])\n",
    "\n",
    "    return np.corrcoef(xs, ys)[0, 1]\n",
    "\n",
    "print(\"Stress vs Distraction:\", correlation_check(\"stress_score\", \"distraction_ratio\"))\n",
    "print(\"Sleep vs Energy:\", correlation_check(\"sleep_hours\", \"daily_energy_level\"))\n",
    "print(\"Debt vs Savings:\", correlation_check(\"debt_pressure_score\", \"savings_ratio\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66f91f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Violations: 0\n"
     ]
    }
   ],
   "source": [
    "def sanity_check(profile):\n",
    "    issues = []\n",
    "\n",
    "    if profile[\"sleep_hours\"] < 5 and profile[\"daily_energy_level\"] > 70:\n",
    "        issues.append(\"Low sleep but high energy\")\n",
    "\n",
    "    if profile[\"sedentary_hours\"] > 10 and profile[\"steps_count\"] > 15000:\n",
    "        issues.append(\"High sedentary but high steps\")\n",
    "\n",
    "    if profile[\"debt_pressure_score\"] > 80 and profile[\"savings_ratio\"] > 60:\n",
    "        issues.append(\"High debt but high savings\")\n",
    "\n",
    "    return issues\n",
    "\n",
    "\n",
    "violations = 0\n",
    "for _ in range(200):\n",
    "    row = X_val.sample(1).iloc[0]\n",
    "    probs = cluster_model.predict_proba(pd.DataFrame([row]))[0]\n",
    "    profile, _ = generate_full_profile(row.to_dict(), probs)\n",
    "\n",
    "    if sanity_check(profile):\n",
    "        violations += 1\n",
    "\n",
    "print(\"Sanity Violations:\", violations)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
